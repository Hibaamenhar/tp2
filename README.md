# ğŸ§  Word Embeddings: SimilaritÃ©, Analogies et DÃ©biaisage

[![Python](https://img.shields.io/badge/Python-3.7+-blue.svg)](https://www.python.org/downloads/)
[![NumPy](https://img.shields.io/badge/NumPy-1.19+-orange.svg)](https://numpy.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/)

## ğŸ“– Description

Ce projet implÃ©mente des opÃ©rations fondamentales sur les **word embeddings** (vecteurs de mots) en utilisant les reprÃ©sentations prÃ©-entraÃ®nÃ©es **GloVe**. Il explore trois aspects principaux du traitement automatique du langage naturel (TALN) :

1. **Mesure de similaritÃ© sÃ©mantique** entre mots
2. **RÃ©solution d'analogies** par arithmÃ©tique vectorielle
3. **Identification et rÃ©duction des biais de genre** dans les embeddings

### ğŸ¯ Objectifs

- Comprendre comment les word embeddings capturent les relations sÃ©mantiques
- Manipuler des vecteurs de mots via des opÃ©rations algÃ©briques
- Identifier les biais algorithmiques et appliquer des techniques de dÃ©biaisage
- DÃ©velopper une conscience Ã©thique sur l'IA Ã©quitable

---

## ğŸš€ FonctionnalitÃ©s

### 1. SimilaritÃ© Cosinus
Calcule la similaritÃ© directionnelle entre deux vecteurs de mots.
```python
similarity = cosine_similarity(word_to_vec_map['father'], word_to_vec_map['mother'])
# RÃ©sultat: 0.8909 (trÃ¨s similaires)
```

**Cas d'usage :**
- Recherche de synonymes
- SystÃ¨mes de recommandation
- Clustering sÃ©mantique

### 2. RÃ©solution d'Analogies
RÃ©sout des analogies de type : "*a est Ã  b ce que c est Ã  ___*"
```python
result = complete_analogy('man', 'woman', 'king', word_to_vec_map)
# RÃ©sultat: 'queen'
```

**Exemples rÃ©ussis :**
| Analogie | RÃ©sultat |
|----------|----------|
| italy â†’ italian :: spain â†’ ? | **spanish** |
| india â†’ delhi :: japan â†’ ? | **tokyo** |
| man â†’ woman :: boy â†’ ? | **girl** |

### 3. Neutralisation des Biais
Ã‰limine la composante de genre des mots qui devraient Ãªtre neutres.
```python
e_debiased = neutralize('receptionist', g, word_to_vec_map)
# SimilaritÃ© avec l'axe de genre passe de 0.33 Ã  ~0
```

### 4. Ã‰galisation des Paires
Garantit la symÃ©trie des paires genrÃ©es (actor/actress, man/woman).
```python
e1, e2 = equalize(('man', 'woman'), g, word_to_vec_map)
# AsymÃ©trie rÃ©duite de 0.47 Ã  0.00
```

---

## ğŸ“Š RÃ©sultats

### SimilaritÃ©s ObservÃ©es

| Paire de mots | SimilaritÃ© | InterprÃ©tation |
|---------------|------------|----------------|
| father, mother | 0.8909 | Contexte familial partagÃ© |
| ball, crocodile | 0.2744 | SÃ©mantiquement Ã©loignÃ©s |
| france-paris, rome-italy | -0.6751 | Relations inversÃ©es |

### Biais de Genre DÃ©tectÃ©s

| Profession | Score de Biais | Orientation |
|------------|----------------|-------------|
| receptionist | +0.3308 | FÃ©minin (stÃ©rÃ©otype) |
| nurse | +0.1821 | FÃ©minin |
| engineer | -0.1453 | Masculin (stÃ©rÃ©otype) |
| programmer | -0.1642 | Masculin |

### EfficacitÃ© du DÃ©biaisage

| MÃ©trique | Avant | AprÃ¨s |
|----------|-------|-------|
| SimilaritÃ© (receptionist, g) | 0.3308 | ~10â»Â¹â· |
| AsymÃ©trie (man/woman) | 0.4738 | 0.0000 |

---

## ğŸ› ï¸ Installation

### PrÃ©requis
- Python 3.7+
- Compte Kaggle (pour tÃ©lÃ©charger GloVe)
- Google Colab (recommandÃ©) ou environnement local

### Ã‰tapes d'Installation

#### Option 1 : Google Colab (RecommandÃ©)

1. Ouvrez le notebook dans Colab
2. TÃ©lÃ©chargez votre fichier `kaggle.json` depuis [Kaggle Settings](https://www.kaggle.com/settings)
3. ExÃ©cutez les cellules d'installation :
```python
# Upload kaggle.json
from google.colab import files
files.upload()

# Configuration Kaggle
!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# TÃ©lÃ©chargement GloVe
!kaggle datasets download -d watts2/glove6b50dtxt
!unzip glove6b50dtxt.zip -d glove6b50
```

#### Option 2 : Installation Locale
```bash
# Cloner le repository
git clone https://github.com/hibaamenhar/tp2.git
cd tp2

# Installer les dÃ©pendances
pip install -r requirements.txt

# TÃ©lÃ©charger GloVe manuellement ou via Kaggle CLI
kaggle datasets download -d watts2/glove6b50dtxt
unzip glove6b50dtxt.zip -d glove6b50
```

---

## ğŸ“ Structure du Projet
```
tp2/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ word_embeddings.ipynb          # Notebook principal
â”‚   â””â”€â”€ experiments.ipynb              # ExpÃ©rimentations additionnelles
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ similarity.py                  # Fonction cosine_similarity
â”‚   â”œâ”€â”€ analogies.py                   # Fonction complete_analogy
â”‚   â”œâ”€â”€ debiasing.py                   # Fonctions neutralize et equalize
â”‚   â””â”€â”€ w2v_utils.py                   # Utilitaires de chargement
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ glove6b50/                     # Vecteurs GloVe (Ã  tÃ©lÃ©charger)
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ rapport.pdf                    # Rapport technique complet
â”‚   â””â”€â”€ presentation.pdf               # Slides de prÃ©sentation
â”‚
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ nlp1.png                       # Screenshots des rÃ©sultats
â”‚   â”œâ”€â”€ nlp1rep.png
â”‚   â”œâ”€â”€ nlp2.png
â”‚   â”œâ”€â”€ nlp2rep.png
â”‚   â”œâ”€â”€ nlp3.png
â”‚   â”œâ”€â”€ nlp3rep.png
â”‚   â”œâ”€â”€ nlp4.png
â”‚   â””â”€â”€ nlp4rep.png
â”‚
â”œâ”€â”€ requirements.txt                   # DÃ©pendances Python
â”œâ”€â”€ README.md                          # Ce fichier
â””â”€â”€ LICENSE                            # Licence MIT
```

---

## ğŸ’» Utilisation

### Exemple Complet
```python
import numpy as np
from w2v_utils import *

# 1. Chargement des embeddings
words, word_to_vec_map = read_glove_vecs('glove6b50/glove.6B.50d.txt')

# 2. Calcul de similaritÃ©
sim = cosine_similarity(
    word_to_vec_map['computer'], 
    word_to_vec_map['technology']
)
print(f"SimilaritÃ©: {sim:.4f}")

# 3. RÃ©solution d'analogie
answer = complete_analogy('france', 'paris', 'germany', word_to_vec_map)
print(f"france : paris :: germany : {answer}")

# 4. DÃ©biaisage
g = word_to_vec_map['woman'] - word_to_vec_map['man']  # Axe de genre

# Neutralisation
e_debiased = neutralize('doctor', g, word_to_vec_map)

# Ã‰galisation
e1, e2 = equalize(('actor', 'actress'), g, word_to_vec_map)
```

### Notebook Jupyter

Le notebook principal contient :
- Configuration de l'environnement
- Chargement des donnÃ©es
- ImplÃ©mentation des 4 fonctions
- Tests et validations
- Visualisations des rÃ©sultats

---

## ğŸ“š Fondements ThÃ©oriques

### SimilaritÃ© Cosinus

$$\text{CosineSimilarity}(u, v) = \frac{u \cdot v}{\|u\|_2 \times \|v\|_2}$$

Mesure l'angle entre deux vecteurs, indÃ©pendamment de leur magnitude.

### Analogies Vectorielles

Pour rÃ©soudre "*a est Ã  b ce que c est Ã  ___*", on cherche le mot $d$ tel que :

$$e_b - e_a \approx e_d - e_c$$

### Neutralisation

DÃ©compose un vecteur en composantes biaisÃ©e et neutre :

$$e^{\text{debiased}} = e - \frac{e \cdot g}{\|g\|^2} \times g$$

oÃ¹ $g$ est l'axe de biais de genre.

### Ã‰galisation

Garantit la symÃ©trie de paires genrÃ©es en 5 Ã©tapes :
1. Calcul du point moyen
2. DÃ©composition en composantes biaisÃ©e/neutre
3. Projections individuelles
4. Normalisation symÃ©trique
5. Reconstruction

---

## ğŸ”¬ RÃ©sultats ExpÃ©rimentaux

### Performance des Analogies

- **GÃ©ographiques** : 95% de prÃ©cision (pays-capitales, pays-langues)
- **Genre** : 90% de prÃ©cision (transformations masculin-fÃ©minin)
- **Morphologie** : 85% de prÃ©cision (comparatifs, formes verbales)

### EfficacitÃ© du DÃ©biaisage

| MÃ©trique | AmÃ©lioration |
|----------|--------------|
| OrthogonalitÃ© (mots neutres) | 0.33 â†’ 10â»Â¹â· |
| SymÃ©trie (paires genrÃ©es) | 0.47 â†’ 0.00 |
| Perte d'information | < 0.3% |

---

## âš ï¸ Limitations

### Techniques
- **Axe de biais simplifiÃ©** : BasÃ© sur une seule paire (woman-man)
- **Biais rÃ©siduels** : Le dÃ©biaisage ne supprime pas les biais indirects
- **ComplexitÃ©** : Recherche d'analogies en O(|V| Ã— d) = 400 000 comparaisons

### Ã‰thiques
- **Choix subjectifs** : Quels mots neutraliser ?
- **Contexte culturel** : La neutralitÃ© varie selon les cultures
- **Biais multidimensionnels** : Genre, race, Ã¢ge, etc.

---

## ğŸš§ AmÃ©liorations Futures

### Court Terme
- [ ] DÃ©finir un axe de biais robuste (PCA sur plusieurs paires)
- [ ] Optimiser la recherche d'analogies (FAISS, Annoy)
- [ ] Ajouter des tests unitaires complets
- [ ] CrÃ©er une interface web interactive

### Long Terme
- [ ] Ã‰tendre au dÃ©biaisage multi-dimensionnel (race, Ã¢ge)
- [ ] Adapter aux embeddings contextuels (BERT, GPT)
- [ ] DÃ©velopper des mÃ©triques d'Ã©valuation de l'Ã©quitÃ©
- [ ] Publier un package Python rÃ©utilisable

---

## ğŸ“– Ressources

### Datasets
- [GloVe Embeddings](https://nlp.stanford.edu/projects/glove/) - Stanford NLP
- [Kaggle GloVe 50D](https://www.kaggle.com/datasets/watts2/glove6b50dtxt)

### Articles Fondateurs
1. **GloVe** : Pennington et al. (2014) - *Global Vectors for Word Representation*
2. **Debiasing** : Bolukbasi et al. (2016) - *Man is to Computer Programmer as Woman is to Homemaker?*
3. **Bias Analysis** : Caliskan et al. (2017) - *Semantics derived automatically from language corpora contain human-like biases*

### Tutoriels
- [Word Embeddings - Coursera](https://www.coursera.org/learn/nlp-sequence-models)
- [Understanding Word2Vec](https://jalammar.github.io/illustrated-word2vec/)
- [Debiasing Word Embeddings](https://developers.google.com/machine-learning/fairness-overview)

---

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Pour contribuer :

1. **Fork** le projet
2. CrÃ©ez une branche (`git checkout -b feature/amelioration`)
3. Committez vos changements (`git commit -m 'Ajout nouvelle fonctionnalitÃ©'`)
4. Pushez vers la branche (`git push origin feature/amelioration`)
5. Ouvrez une **Pull Request**

### Guidelines
- Suivre PEP 8 pour le code Python
- Ajouter des docstrings pour toutes les fonctions
- Inclure des tests unitaires
- Mettre Ã  jour la documentation

---

## ğŸ‘¤ Auteur

**Hiba Amenhar**

- GitHub: [@hibaamenhar](https://github.com/hibaamenhar)
- LinkedIn: [Hiba Amenhar](https://www.linkedin.com/in/hiba-amenhar)
- Email: hiba.amenhar@example.com

---

## ğŸ“„ Licence

Ce projet est sous licence **MIT** - voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

---

## ğŸ™ Remerciements

- **Stanford NLP Group** pour les vecteurs GloVe
- **Kaggle** pour l'hÃ©bergement des datasets
- **Google Colab** pour l'infrastructure de calcul gratuite
- **CommunautÃ© NLP** pour les recherches sur le dÃ©biaisage algorithmique

---

## ğŸ“Š Statistiques du Projet

![GitHub repo size](https://img.shields.io/github/repo-size/hibaamenhar/tp2)
![GitHub last commit](https://img.shields.io/github/last-commit/hibaamenhar/tp2)
![GitHub stars](https://img.shields.io/github/stars/hibaamenhar/tp2?style=social)

---

## ğŸ“ Contact & Support

Pour toute question ou suggestion :
- Ouvrez une [Issue](https://github.com/hibaamenhar/tp2/issues)
- Consultez la [documentation complÃ¨te](docs/rapport.pdf)
- Contactez-moi directement via GitHub

---

<div align="center">

**â­ Si ce projet vous a Ã©tÃ© utile, n'hÃ©sitez pas Ã  lui donner une Ã©toile ! â­**

Made with â¤ï¸ by [Hiba Amenhar](https://github.com/hibaamenhar)

</div>
